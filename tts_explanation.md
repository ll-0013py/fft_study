# 現代社会の合成音声

## 始めに

Siri や Google アシスタントをはじめとした合成音声（Text-to-Speech）は今日で幅広く普及してきていて、当然昔よりもより人間に近くて感情豊かなものが出来上がってきています。

日本語合成音声（特に Miscrosoft Azure など）の進歩も目覚ましいですが、特に英語なんかだと 9 割以上ネイティブスピーカーとの聞き分けが付かない品質に到達しているんだとか。日本語 TTS は開発者が少ないというのもありますが、人間を超える日も近いのかもしれませんね。

## TTS のメリットデメリット

### メリット

- ショートカット（アプリを開いてー、とかしなくても一発で目的の動作が実行可能）
  文字入力の手間の削減
- 手ぶらでよく、自由な操作姿勢
- 条件付きの指示が可能、曖昧な表現が許容される
- コミュニケーション体験価値を生む
- 感情や心理状況が反映される
- 音声には特に文化や言語の違いが影響する

### デメリットと課題点

- 伝言ゲームの様になってしまう
- いつ何をどう言えばいいのか分からない
- 現状がわからない
- 音声認識が不確実
- 発話は労力が必要
- しかし自動ドアや人感センサーの方が楽ではある
- 音声は単純な操作が苦手
- カーソルをちょっと上に動かして、など
- マジックワード、ウェイクワード（呼び出すときの言葉）がまどろっこしい
- 不自然な発話問題
- 留守番電話だと焦ってしまう。書き言葉と話し言葉の違い
- 発話環境に依存する
- 周りの環境だけでなく、喉の調子にも依存
- 発話までの間が長い
- 人間の対話では基本的に 1 秒未満の間しか空かない
- 絵文字、顔文字なし
- 音声入力中の割り込み、キャンセルに対応できない

他に挙げられる課題点としては以下のようなものがあります。

- 間違えて買い物をしてしまった場合にどうなるのか
  - 買うものを決めるまで、が音声アシスタントの役割？
- 日本の TTS の開発が遅れている
- 男女による言葉づかいの差も考えなくてはいけない
- ボーカロイドはそれ自体で独自の文化を作っているため、声質の改良が常に正義化と言われると難しい
- 音声認識のレベルは 9 割以上であるが、名前などだと読み間違いが多い
- 使うのが恥ずかしいと考えている人もいる
- 宣伝があまりなされていない
- 落語とかで考えたら、よどみなども本来取り除くべきであるが、表現したほうがいいのかもしれない。どこまで表現すればよいのかが不明瞭
- 合成音声と喧嘩する人はいない
  - 機械としての認識しかされていない
  - 価値関数といって、損をしたほうが印象に残るので、そのせいかも
- あまり面白いと思われていない
  - 吉本興業とソフトバンクがコラボして面白い受け答えのデータを用意したが、Pepper君はすぐに飽きられてしまった

### まとめとか考察

合成音声の登場によって、ボタンやキーボードなどの物理的な UI から、音声による UI へと入力が変化しました。文字ではなく音声だからこそ感情表現が豊かになることが期待されています。

話し方だけ取ってみても、「東京は明日雪ですか？」とかしこまりまらなくても、「明日雪だっけ？」「そうそう、東京で。」などの聞き方をすることもできます。倒置や繰り返しなどがありますが、ここでは TTS 側が文化や言語の違いをいかに吸収するかが重要。

ただ、機械と話していると人と違って緊張してしまう人もいるので、こうならないように心理的な側面を和らげる（経験価値をつける）UX デザインも必要になってきます。

## 実用化の例

- シーマン：言葉が認識できないと「何言ってるんだ、もう寝るよ」と言う。ユーザーに責任転嫁することで友情関係が生まれた
- 女子高生 AI りんな
  マイクロソフトの開発。機械学習と大量の集積データからそれっぽい返事をする（教師あり学習）
- 米ニュアンス・コミュニケーションズ：音声認識のすごい会社。Siri やシャープの音声アシスタントなどにも技術が使われている
- コンシェルジュサポート：大阪大学の研究で、積極的にいてほしいとは思わないが、ロボットがいる分には構わず、楽しい気分になる、とされている
- 防犯カメラとしてのスマートスピーカーの設置
- 電車のアナウンス：昔はパーツ（駅名と助詞など）ごと組み合わせていた
- 携帯電話：実はこれもそれっぽい声を再現しているだけに過ぎない

## TTS でできること

- 情報検索
- 予定管理・タイマー・アラーム
- 連絡
- メディアプレイヤー
- 音楽など
- wifi などの機器連携
- 雑談・エンターテイメント

## 未来アイデア

TTS 界隈では、情報処理学会、人工知能学会、音響学会、心理学学会、日本語教育学会などで音声対話システムについて扱われているため、人、言葉、文化、などの IT 以外の学問も必要になってきている。

声の著作権のために、合成音声と生の声の見分けがつくようにしなくてはいけない。例えば、吐息が合成音声には入っていないことを利用すれば悪用が防げたりしそうである。東芝なんかは合成音声だけに特有な目印を残すようにしている。

品詞ごとにアクセントのミスをはさませ、どの品詞のアクセントミスで最も評価が下がるのか、アクセントやイントネーションなどの韻律の要素を用意し、どれをおかしくしたときに評価が下がるのかを調べたい。

情報を伝えるという役割は果たしているので、その先を目指したい。例えば...

- 落語やお笑い
- 方言の保存
- 声優さんの負担削減
- 障碍者の声のサポート

## 主要な生成方式

で、これらはどうやって作られているのかというと、今までは大きく分けて 3 つの手法が取り入れられていました。

1. 波形接続型合成（素片選択型合成）方式
2. パラメトリック合成方式
3. ハイブリッド合成方式

### 波形接続型合成（素片選択型合成）方式

まず波形接続型合成というのは、録音した大量の人間の音声から必要な部分のみ切り取ってペタペタと合成していく手法のことです。1990~2000 年代に主流だったもので、初代ボーカロイドやひと昔前までの Google 合成音声なんかがこれに当たります。制作には専門知識が必要です。

### パラメトリック合成方式

二つ目のパラメトリック合成というのは、機械学習などを用いてデータ導き出したパラメトリック生成モデルの出力を元に音声パラメータを表現し、音声を合成する方式です。HMM（隠れマルコフモデル）なども利用されていて、ニューラルネットワークが熱いです。喜怒哀楽（恐れや楽しみがある 5 感情も）にも対応しています。

声質は波形接続型合成と比べると高くないですが、素材を選ばない分柔軟で高速な合成が可能になります。2000 年代くらいから流行りだしました。電車の音声や初期のボカロがこの方式です。これにより TTS の作成は半分くらい自動化が進んだわけですが、以前として専門知識も必要でした。

ニュアンスコミュニケーションズの「Zuance Vocalizer」、HOYAS「VoiceText Micro」、グーグルの「Google 音声合成」、フュートレックの「音声合成エンジン」などは上記の HMM 技術を使用しています。
また、他にも「DNN」 (Deep Neural Network)などの機械学習を使ったモデルも利用されているます。

ちなみに、パラメトリック音声合成では、音響特徴量の分析とボコーダーによる音声波形の生成が別々であったため、音響特徴量を利用せずに言語特徴量から音声波形を直接生成していました。

#### 実際の音声合成プロセス

で、実際のパラメトリック合成方式のだと、TTS にテキストが入力されてから音声が出力されるまでには、

1. テキスト解析
2. 音声分析
3. 波形合成

みたいなプロセスを踏んで操作がされています。

##### 1. テキスト解析

テキスト解析は単自然言語処理で形態素解析などをするだけでなく、近年では感情のこもった分析、ニュースの読み上げ、などの場面コンテクストによって分析を変えているそうです。これにより、適切な発音やイントネーションが選択されます。

発話の内容とその意図を理解するプロセスと思ってもらえるといいです。例えばこんなものが含まれますね。

- 形態素解析―意味を持つ最小単位に分解。品詞分解する。
- 構文解析―形態素を解析。関係性を明らかにし、なにがどうしたかを理解する
- 意味解析―文章の意味を理解。知識やルールを使う。知識、ルールを利用
- 照応解析―代名詞や、そこ、それなどの省略された言葉が何を指すのか推定する

##### 2. 音声分析

音声分析というのは、ソース・フィルタ理論に基づくスペクトル包絡を利用してどのような音声波形を合成すればよいかをモデルとして考えるプロセスです。このモデルでは、発音やアクセント、音の長さなどの要素を考慮して、自然な音声を合成しています。

##### 3. 波形合成

波形合成では、音声のパラメーターから生成した音源波形に、スペクトル包絡パラメータから合成した合成フィルタを畳みこんで実際の音声を作っていきます。

#### 利点

- 学習データ量が少なくてよく、1h 程度あれば十分
- 統計モデルを用いているため読みやアクセントなどを調節したい場合、それぞれのモジュールを個別に調節できる
- 録音データを利用しているわけではないため動作が軽量
- 音声の感情なども調節できる

#### 欠点

- 音質がよくない
- 各モジュールが独立しているため、全体的に見たときに最適ではない場合がある
- 専門知識が必要でシステムが複雑

#### ソース・フィルタ理論

これに対して品質を高める取り組みの一つとしては、ソース・フィルタ理論のモデル化が挙げられます。ソース・フィルタ理論というのは、声道によって生成されるソース（音源）が声道により音色づけられる（フィルタ）という考え方のことです。

こちらは、最初は有声音にインパルス列、無声音に白色雑音を与えてソース信号を離散的に切り替えていました。しかし、ブザーのような音声しか合成できないのが問題点でした。

そのため、その後はインパルス列と雑音を連続的に切り替えるようにしました。結果として、有声音の時にも雑音を少し入れることによって高音質な音声を合成できるようになりました。混合励振動とも呼ばれて、WORLD などでも使用されている技術です。

### ハイブリッド合成方式

三つ目のハイブリッド合成方式というのは、名前の通り上記の二つを組み合わせたものですね。2017 年あたりの Apple の Siri なんかがこの手法を用いていたようです。

周波数や音色から音声波形を人工的に作るフォルマント合成というのもあるにはあるらしいですが、子音を作るのが下手でロボット的な音声になるっぽいです。あんまり使われているのを聞いたことはありません。

### 一貫学習に基づく音声合成

ただ、ここ最近（2010 年代後半）ヤバい手法が出てきて、これにより全ての合成音声の生成プロセスが自動化されました。それが一貫学習に基づく音声合成方式です。

例えば 2016 年に DeepMind が発表した WaveNet や 2018 に Google が発表した Tacotron 2 などです。DeepMind は時間はかかりますが音声波形を直接生成可能で品質が高く、Tacotron 2 はシステムが簡潔で自然な音声を作ることができるという特徴があります。

学習に必要なデータ量も削減されていて、2016 年の WaveNet では約 24 時間の録音コーパスが使われていたらしいですが、今の時代は 1 時間位あれば十分らしいです。高音質なデータを大量に用意するのは声のモデルさんとしてもエンジニアとしてもコストがかかりますから、これは嬉しいですね。

一貫学習に基づく音声合成では、各モジュールの連結をニューラルネットワークで置換しています。こちらの方式の TTS では統計的パラメトリック音声合成よりも性能がよく、人間とあまり変わらないとされています。例えば WaveNet では、人間の声の評価が 4.5 に対して 4.15 程度の評価を記録しました。

## 統計や機械学習について

### 統計検定について

- 比率尺度：四則演算ができる。一般的には物理的な尺度（重さ、速さ）
- 間隔尺度：計算できるが、\* / はできない（気温、時間）
- 順序尺度：順序の意味はあるが、間隔は一定ではないもの（1.好き、2.普通...）
- 名義尺度：学籍番号や郵便番号

順序尺度と間隔尺度：マラソンの順位 → 数字 1 つの差が一定でない場合は順序尺度である。

間隔尺度と比率尺度：〇倍や〇割に意味がある → 比例尺度である。

良く誤解されがちだが、相関係数はデータの線形関係を見つけるだけで因果関係を説明しているわけではない。年収とカロリーの間の「年齢」のように、疑似相関がみられる可能性もあるので注意。

### モデル化

パラメトリック合成方式で出てきた「モデル化」について説明します。

そもそもモデルってなんだ、って話になると思いますが、具体的には統計的パラメトリック音声合成で生成される統計モデルは音響モデルと呼ばれます。様々な言語特徴量から音響特徴量を予測することによって、波形合成に向けて適切なパラメータを作ろうとしているわけです。

とは言っても、モデル化そのものを行う際には（実際には人間の読み上げる音声はいつも同じものではないため）人間の音声が何かしらの確率分布に従っていると考えて学習を行います。
ここでは生成モデル（確率変数の同時分布をモデル化している）が主に用いられます。条件付確率の場合は識別モデルといいます。

音声波形の集合とテキストの集合が与えられた場合、そこから予測分布を作り（天気と今日は一緒に使われやすい、など）、これをもとに未知のテキストが来た時にも音声を合成することができるようにする訳です。
ただ、現実問題これらをテキスト、波形から直接モデル化することは困難であるので、テキストの言語特徴量や音声の音響特徴量を抽出して、それぞれを関連させながら（条件付確率）表現することで問題を簡単にしているっぽいです。

ただし、必ずしも分布仮説にとらえられるわけではなく、「泳げないことはない」などではまだ難しかったりするので、自然言語処理の中でも理論言語学（数学などの論理で言語を定義する）などの分野を進めていく必要があります。これにより、内部の判断がブラックボックス化されているという課題があります。

### 機械学習の手法について

主なものを書いてみます。

**教師あり学習:**

1. **k-近傍法:**

- 近くのデータの多数決で予測を行う単純な手法。直感的で理解しやすいが、大規模データには向かない。

2. **ランダムフォレスト（バギング）:**

- 複数の決定木を組み合わせ、ブートストラップサンプリングとランダムな特徴の選択により高い汎化性能を持つモデルを構築。

3. **Xgboost、LightGBM（ブースティング）:**

- 前のモデルの誤差に焦点を当て、徐々に修正していくアンサンブル手法。高い精度と効率を実現し、大規模データや複雑なパターンに適している。

**教師なし学習:**

1. **クラスター分析（k-means 法):**

- データを予め指定したクラスタ数に分割し、各クラスタ内のデータが似ている特徴を持つ。データの構造を把握するのに有用。

2. **主成分分析:**

- 多次元データをより少ない次元で表現する手法。データの情報損失を最小限にしながら、データの変動を捉え、次元の圧縮や特徴抽出に利用される。

### 実際の TTS で使われているもの

まず、基本的にテキスト解析の段階では、音素で区切って分析しています。
あとは、HMM では計算が間に合わないので N-gram（任意の文字数で文章を分割する手法。T 個の単語からなる文において T-n+1 個の n-gram の区切りがある）などの自然言語処理による予想もしているようです。

具体的な手法には重回帰分析やニューラルネットワークなど様々なものがありますが、決定木を使用していることも多いです。
従来は非線的な特徴をうまくモデル化できないという問題点があったわけですが、これによって直感的に人間に理解がしやすくモデル構築が容易になる、という利点があります。

### 隠れマルコフモデル（HMM：Hidden Markov Model）

#### マルコフ過程

まずマルコフ過程というモデルがあって、こちらは未来の状態が現在の状態に依存し、過去の状態には依存しないというマルコフ性をもつ確率分布の一種です。

例えば、毎日 12 時にご飯を食べるかパンを食べるか完全にランダムで決める人がいたとすると、この人はマルコフ性を持っています。昨日パンを食べたとかそういうことは関係なく、その日の 12 時にどちらを選択するかを決めるからです。

データの話にはなりますが、離散時間なら離散状態の系列、連続したものなら連続的な時間におけるの確率分布として機能します。

マルコフプロセス（離散時間）は、遷移確率行列 \(P\) を使用して次のように表されます。

$$
P(X_{t+1} = j | X_t = i) = P_{ij}
$$

- \(X_t\) は時刻 \(t\) における状態
- \(P\_{ij}\) は状態 \(i\) から状態 \(j\) への遷移確率
- \(t\) は時間ステップ

遷移確率行列 \(P\) は次のように表されます。

$$
P = \begin{bmatrix} P_{11} & P_{12} & \cdots & P_{1n} \\ P_{21} & P_{22} & \cdots & P_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ P_{n1} & P_{n2} & \cdots & P_{nn} \end{bmatrix}
$$

この行列の \(i\) 行 \(j\) 列の要素 \(P\_{ij}\) は、状態 \(i\) から状態 \(j\) への遷移確率を示します。各行の要素の合計は 1 になります。

#### 隠れマルコフモデル

「隠れ」マルコフモデルとはなにかというと、さっきの例でいう「ご飯とパンを完全ランダムで選ぶ」などの内部の状態は直接観測されず、その結果（出力）のみが観測される確率分布のことです。

この出力だけしか見えませんが、それでも内部はモデルの状態によって確率分布が表されています。なので、外部から観測できる事象を手掛かりに内部のモデルを予想することができます。

以下、隠れマルコフモデル (HMM) の基本的な数式と説明です。

**1. 状態遷移確率 (State Transition Probability):**

$$
a_{ij} = P(q_t = S_j | q_{t-1} = S_i)
$$

- \( a\_{ij} \): 状態 \( S_i \) から \( S_j \) への遷移確率

**2. 観測確率 (Emission Probability):**

$$
b_j(k) = P(o_t = V_k | q_t = S_j)
$$

- \( b_j(k) \): 状態 \( S_j \) での観測 \( V_k \) の確率

**3. 初期状態確率 (Initial State Probability):**

$$
\pi_i = P(q_1 = S_i)
$$

- \( \pi_i \): 初期状態が \( S_i \) である確率

**4. 前向きアルゴリズム (Forward Algorithm):**

$$
\alpha_t(j) = P(o_1, o_2, ..., o_t, q_t = S_j | \lambda)
$$

- \( \alpha_t(j) \): 時刻 \( t \) までの観測と状態 \( S_j \) の生成確率
- \( \lambda \): HMM のパラメータ (遷移確率、観測確率、初期状態確率)

**説明:**

- HMM は系列データ生成のプロセスをモデル化します。
- a\_{ij} は状態間の遷移確率、b_j(k) は状態 S_j での観測 V_k の確率です。
- \pi_i は初期状態確率、\alpha_t(j) は前向きアルゴリズムで計算され、時刻 t までの観測と状態 S_j の生成確率を示します。

#### TTS での利用

HMM は何に使われているのかというと、TTS の場合はテキスト分析の際に HMM を持ちて「この言葉が来たから次はこうなるだろう」などと予想したいわけです。

HMM の状態は、音声の異なる音素や音響特徴を表現します。各状態は、音声信号のある時点における特徴をモデル化します

例として音素モデリングを考えてみます。
音素は言語の最小音声単位であり、それぞれの音素に対して HMM が学習できます。各音素には複数の状態変化が対応してくるわけですが、HMM は音素の音響的な変化をモデル化します。

具体的には、その後、TTS システムはテキストから音素列を生成し、それに対応する HMM を用いて合成音声を生成します。
HMM は音声の生成過程を確率的にモデル化しているため、異なる音声のバリエーションであったとしても自然に表現することができるわけです。

## 用語解説

### 言語・音声処理

- 等時性（Timing）: 言語の時間的要素。日本語はモーラ、中国語は一拍に漢字一文字。
- 朗読音声（TTS）: テキストを読み上げる技術。自発音声とも呼ばれる。
- ボコーダー: 音声のパラメーターから音声波形を合成する技術。

### 音声処理・モデリング

- 隠れマルコフモデル（HMM）: 音声の時間的変化を考慮した生成モデル
- LPC（Linear Predictive Coding）: 音声の線形予測分析。
- 混合ガウスモデル: 複数のガウスモデルで音声分布をモデリング。

### 統計・予測モデル

- AIC（Akaike's Information Criterion）: モデルの適合度と複雑さを評価する指標。
- 回帰分析: 統計的な予測モデル

### 評価法

- 客観的評価法: 物理量から評価。声の忠実さや雑音除去の指標。

### 機械学習

- ニューラルネットワーク: 神経細胞を模した学習モデル。

### 統計関連

- バイアス（Bias）: 推定結果と実測値との差。結果のばらつきとトレードオフがある。